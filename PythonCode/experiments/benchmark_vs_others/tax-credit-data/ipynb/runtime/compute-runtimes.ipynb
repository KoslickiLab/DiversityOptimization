{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the environment\n",
    "-----------------------\n",
    "\n",
    "First we'll import various functions that we'll need for generating the report and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, expandvars, abspath\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tax_credit.framework_functions import (runtime_make_test_data,\n",
    "                                            runtime_make_commands,\n",
    "                                            clock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## project_dir should be the directory where you've downloaded (or cloned) the \n",
    "## tax-credit repository. \n",
    "project_dir = '../..'\n",
    "data_dir = join(project_dir, \"data\")\n",
    "\n",
    "results_dir = join(project_dir, 'temp_results_runtime')\n",
    "runtime_results = join(results_dir, 'runtime_results.txt')\n",
    "tmpdir = join(results_dir, 'tmp')\n",
    "\n",
    "ref_db_dir = join(project_dir, 'data/ref_dbs/gg_13_8_otus')\n",
    "ref_seqs = join(ref_db_dir, '99_otus_clean.fasta')\n",
    "ref_taxa = join(ref_db_dir, '99_otu_taxonomy_clean.tsv')\n",
    "\n",
    "num_iters = 1\n",
    "sampling_depths = [1, 4000] #[1] + list(range(2000,10001,2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test datasets\n",
    "Subsample reference sequences to create a series of test datasets and references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_make_test_data(ref_seqs, tmpdir, sampling_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import to qiime for q2-feature-classifier methods, train scikit-learn classifiers. We do not include the training step in the runtime analysis, because under normal operating conditions a reference dataset will be trained once, then re-used many times for any datasets that use the same marker gene (e.g., 16S rRNA). Separating the training step from the classification step was a conscious decision on part of the designers to make classification as quick as possible, and removing redundant training steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported ../../data/ref_dbs/gg_13_8_otus/99_otu_taxonomy_clean.tsv as HeaderlessTSVTaxonomyFormat to ../../data/ref_dbs/gg_13_8_otus/99_otu_taxonomy_clean.tsv.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/1.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/1.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/1.fna.nb.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/2000.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/2000.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/2000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/4000.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/4000.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/4000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/6000.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/6000.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/6000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/8000.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/8000.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/8000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mImported ../../temp_results_runtime/tmp/10000.fna as DNASequencesDirectoryFormat to ../../temp_results_runtime/tmp/10000.fna.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/10000.fna.nb.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! qiime tools import --input-path {ref_taxa} --output-path {ref_taxa}.qza --type \"FeatureData[Taxonomy]\" --input-format HeaderlessTSVTaxonomyFormat\n",
    "\n",
    "for depth in sampling_depths:\n",
    "    tmpfile = join(tmpdir, str(depth)) + '.fna'\n",
    "    ! qiime tools import --input-path {tmpfile} --output-path {tmpfile}.qza --type \"FeatureData[Sequence]\"\n",
    "    ! qiime feature-classifier fit-classifier-naive-bayes --o-classifier {tmpfile}.nb.qza --i-reference-reads {tmpfile}.qza --i-reference-taxonomy {ref_taxa}.qza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the method/parameter combinations\n",
    "\n",
    "Finally we define the method, parameter combintations that we want to test and command templates to execute.\n",
    "\n",
    "Template fields must adhere to following format:\n",
    "\n",
    "                      {0} = output directory\n",
    "                      {1} = input data\n",
    "                      {2} = reference sequences\n",
    "                      {3} = reference taxonomy\n",
    "                      {4} = method name\n",
    "                      {5} = other parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_template = ('qiime feature-classifier classify-consensus-blast --i-query {1}.qza --o-classification '\n",
    "                  '{0}/assign.tmp --i-reference-reads {2}.qza --i-reference-taxonomy {3}.qza {5}')\n",
    "vsearch_template = ('qiime feature-classifier classify-consensus-vsearch --i-query {1}.qza '\n",
    "                    '--o-classification {0}/assign.tmp --i-reference-reads {2}.qza --i-reference-taxonomy {3}.qza {5}')\n",
    "naive_bayes_template = ('qiime feature-classifier classify-sklearn  '\n",
    "                        '--o-classification {0}/assign.tmp --i-classifier {2}.nb.qza --i-reads {1}.qza {5}')\n",
    "mindivlp_template = ('python ../../../classify_mindivlp.py -i {1} -o {0} -r {2} -t {3} -p') # PythonCode/experiments/benchmark_vs_others\n",
    "\n",
    "# {method: template, method-specific params}\n",
    "methods = {\n",
    "    #'blast+' : (blast_template, '--p-evalue 0.001'),\n",
    "    #'vsearch' : (vsearch_template, '--p-perc-identity 0.90'),\n",
    "    #'naive-bayes': (naive_bayes_template, '--p-confidence 0.7'),\n",
    "    'mindivlp': (mindivlp_template, '-s 8 -l 12 -c 1000 -q 0.01')\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the list of commands and run them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will vary the size of the reference database and search a single sequence against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_a = runtime_make_commands(tmpdir, tmpdir, methods, ref_taxa,\n",
    "                                   sampling_depths, num_iters=1, subsample_ref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will vary the number of query seqs, and keep the number of ref seqs constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_b = runtime_make_commands(tmpdir, tmpdir, methods, abspath(ref_taxa),\n",
    "                                   sampling_depths, num_iters=1, subsample_ref=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first command in each list and the total number of commands as a sanity check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e79bf79ac507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands_a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcommands_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "commands_a = [('python ../../../classify_mindivlp.py -i ../../temp_results_runtime/tmp/1.fna -o ../../temp_results_runtime/tmp -r ../../temp_results_runtime/tmp/4000.fna -t ../../data/ref_dbs/gg_13_8_otus/99_otu_taxonomy_clean.tsv -p', 'mindivlp', '1', '4000', 0)]\n",
    "commands_b = []\n",
    "\n",
    "print(len(commands_a + commands_b))\n",
    "print(commands_a[1])\n",
    "print(commands_b[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=1)(delayed(clock_runtime)(command, runtime_results, force=False) for command in (list(set(commands_a + commands_b))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
